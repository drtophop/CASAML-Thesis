{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWSS4vxy/Ooze34CryfMwi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drtophop/CASAML-Thesis/blob/main/CAS_AML_Thesis_NguyenHop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dcda3e5-ad82-472c-bc72-5310a1e59683"
      },
      "source": [
        "# CAS AML Thesis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "RP6iW0pm11q6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scope"
      ],
      "metadata": {
        "id": "x9T7lebI6Vq3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Contents"
      ],
      "metadata": {
        "id": "W6SlaM6Y1-Si"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sources"
      ],
      "metadata": {
        "id": "FEqRMsT72Mg6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remarks"
      ],
      "metadata": {
        "id": "C8uZGoGP6ZVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries and Modules"
      ],
      "metadata": {
        "id": "OZ0gVTtB5-yJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "EJcI1g4rYETg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import  time, random\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "dNQggfP-XvBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "GkQHhQ0sX08x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "from IPython.display import clear_output\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "w43wbFBYX3RJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml"
      ],
      "metadata": {
        "id": "s4y-vwhCX7CZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ],
      "metadata": {
        "id": "GghZXjVcX9H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import io\n",
        "import cv2\n",
        "import json"
      ],
      "metadata": {
        "id": "qE_thxM5X_Hz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "KWcdBGLTYBgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Numpy"
      ],
      "metadata": {
        "id": "W2Od1BeZ6GPm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Opendatasets"
      ],
      "metadata": {
        "id": "B24N-dSK-_QG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The opendatasets Python package, provides a convenient way to download and work with open datasets from various sources"
      ],
      "metadata": {
        "id": "WsQC_QUK_VXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "id": "zVSvlT_u-8ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets"
      ],
      "metadata": {
        "id": "93Mpzn8x6Iou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Local Folder"
      ],
      "metadata": {
        "id": "EP_BIGwi7i0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_main = os.getcwd()"
      ],
      "metadata": {
        "id": "8MAJMQIK7oev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Object Recognition"
      ],
      "metadata": {
        "id": "PWvWM4q86Pie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "od.download('https://www.kaggle.com/datasets/sshikamaru/car-object-detection/download?datasetVersionNumber=2')"
      ],
      "metadata": {
        "id": "Eg7dqn5DYSMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Object Segmentation"
      ],
      "metadata": {
        "id": "NjiVGRsp6fBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Object Recoginition with Yolov5"
      ],
      "metadata": {
        "id": "4ZnMlbXc7CdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the String for the detection dataset folder\n",
        "path_yoloset = f'{path_main}/car-object-detection/data'"
      ],
      "metadata": {
        "id": "UsCXoMQZ8FJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Clear locals"
      ],
      "metadata": {
        "id": "T7bmbKBg7LsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before starting with the Yolov5, existing contents and existing folders from a potentional former execution of this Notebook will be cleared to show proper execution, by following expressions"
      ],
      "metadata": {
        "id": "eupjOGmu8hlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dirs_to_delete = ['car-object-detection', 'yolov5', 'test', 'tmp', 'train', 'valid', 'yolov5_train']\n",
        "\n",
        "for dir_to_delete in dirs_to_delete:\n",
        "    path_del = os.path.join(path_main, dir_to_delete)\n",
        "    if os.path.exists(path_del):\n",
        "        shutil.rmtree(path_del)\n",
        "\n",
        "files_to_delete = ['data.yaml','yolov5m6.pt']\n",
        "\n",
        "for file_to_delete in files_to_delete:\n",
        "    file_del = os.path.join(path_main, file_to_delete)\n",
        "    if os.path.exists(file_del):\n",
        "        os.remove(file_del)"
      ],
      "metadata": {
        "id": "a2hEQs2H9SA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clone and Setup Yolo V5"
      ],
      "metadata": {
        "id": "FmFuOUmQ9rfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone yolov5 from the corresponding Git Repository to Local\n",
        "!git clone https://github.com/ultralytics/yolov5"
      ],
      "metadata": {
        "id": "fStg9AF49o0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the required Python packages specified in the requirements.txt file within the yolov5 directory\n",
        "!pip install -qr yolov5/requirements.txt"
      ],
      "metadata": {
        "id": "rtlMtyfV-Yp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialization"
      ],
      "metadata": {
        "id": "yuxoMnhzAjVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up the Hyperparameters to run yolov5"
      ],
      "metadata": {
        "id": "jyuUu1nuBN8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_NAME = \"yolov5_train\"\n",
        "BASE_MODEL = \"yolov5m6.pt\"\n",
        "TRAIN_BATCH = 32\n",
        "TRAIN_EPOCHS = 20\n",
        "VAL_BATCH = 64\n",
        "\n",
        "\n",
        "# Doublecheck if needed Folders are ok\n",
        "print(f'does path_main exist: {os.path.exists(path_main)}')\n",
        "print(f'does path_yoloset exist: {os.path.exists(path_yoloset)}')"
      ],
      "metadata": {
        "id": "tfCOZi_k-t8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_h, img_w, num_channels = (380, 676, 3)\n",
        "\n",
        "df = pd.read_csv(f'{path_yoloset}/train_solution_bounding_boxes (1).csv')\n",
        "\n",
        "df.rename(columns={'image':'image_id'}, inplace=True)\n",
        "df['image_id'] = df['image_id'].apply(lambda x: x.split('.')[0])\n",
        "df['x_center'] = (df['xmin'] + df['xmax'])/2\n",
        "df['y_center'] = (df['ymin'] + df['ymax'])/2\n",
        "df['w'] = df['xmax'] - df['xmin']\n",
        "df['h'] = df['ymax'] - df['ymin']\n",
        "df['classes'] = 0\n",
        "df['x_center'] = df['x_center']/img_w\n",
        "df['w'] = df['w']/img_w\n",
        "df['y_center'] = df['y_center']/img_h\n",
        "df['h'] = df['h']/img_h\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "zJtMkDMLYk2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = list(set(df.image_id))\n",
        "image = random.choice(index)\n",
        "print(\"Image ID: %s\"%(image))\n",
        "\n",
        "img = cv2.imread(f'{path_yoloset}/training_images/{image}.jpg')\n",
        "img.shape"
      ],
      "metadata": {
        "id": "2SbTFZU0Yn_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adde here cose"
      ],
      "metadata": {
        "id": "CAVazeKaYoqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source = 'training_images'\n",
        "\n",
        "for name, mini in tqdm(df.groupby('image_id')):\n",
        "    if not os.path.exists(os.path.join(path_main, 'tmp', 'labels')):\n",
        "        os.makedirs(os.path.join(path_main, 'tmp', 'labels'))\n",
        "\n",
        "    with open(os.path.join(path_main, 'tmp', 'labels', '{}.txt'.format(name)), 'w+') as f:\n",
        "        row = mini[['classes', 'x_center', 'y_center', 'w', 'h']].astype(float).values\n",
        "        row = row.astype(str)\n",
        "        for j in range(len(row)):\n",
        "            text = ' '.join(row[j])\n",
        "            f.write(text)\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    if not os.path.exists(os.path.join(path_main, 'tmp', 'images')):\n",
        "        os.makedirs(os.path.join(path_main, 'tmp', 'images'))\n",
        "\n",
        "    shutil.copy(\n",
        "        os.path.join(path_yoloset, source, '{}.jpg'.format(name)),\n",
        "        os.path.join(path_main, 'tmp', 'images', '{}.jpg'.format(name))"
      ],
      "metadata": {
        "id": "Rw7QRpbTYrfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGES_PATH = f'{path_main}/tmp/images/'\n",
        "LABELS_PATH = f'{path_main}/tmp/labels/'\n",
        "os.path.exists(IMAGES_PATH)"
      ],
      "metadata": {
        "id": "LbyLyCKQYupZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read labels\n",
        "labels = os.listdir(LABELS_PATH)\n",
        "\n",
        "\n",
        "# Split data\n",
        "train, test = train_test_split(labels, test_size=0.15, shuffle=True)\n",
        "valid, test = train_test_split(test, test_size=0.2)\n",
        "\n",
        "print(f\"train: {len(train)}; valid: {len(valid)}; test: {len(test)}\")"
      ],
      "metadata": {
        "id": "hlEZksLsYyLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(f'{path_main}/test/images')\n",
        "os.makedirs(f'{path_main}/test/labels')\n",
        "os.makedirs(f'{path_main}/train/images')\n",
        "os.makedirs(f'{path_main}/train/labels')\n",
        "os.makedirs(f'{path_main}/valid/images')\n",
        "os.makedirs(f'{path_main}/valid/labels')"
      ],
      "metadata": {
        "id": "9ZqThILLY0px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to move files to directory\n",
        "def move_files_to_dir(files, dirname):\n",
        "    # Create target directories if they don't exist\n",
        "    os.makedirs(f'{path_main}/{dirname}/images', exist_ok=True)\n",
        "    os.makedirs(f'{path_main}/{dirname}/labels', exist_ok=True)\n",
        "\n",
        "    for label_filename in files:\n",
        "        image_filename = f\"{label_filename[:-4]}.jpg\"\n",
        "        shutil.copy(f\"{IMAGES_PATH}/{image_filename}\", f\"{path_main}/{dirname}/images/{image_filename}\")\n",
        "        shutil.copy(f\"{LABELS_PATH}/{label_filename}\", f\"{path_main}/{dirname}/labels/{label_filename}\")\n",
        "\n",
        "\n",
        "# Move splits to folders\n",
        "move_files_to_dir(train, \"train\")\n",
        "move_files_to_dir(test, \"test\")\n",
        "move_files_to_dir(valid, \"valid\")\n"
      ],
      "metadata": {
        "id": "WBTGFMBjY2d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directories = ['train', 'test', 'valid']\n",
        "subdirectories = ['images', 'labels']\n",
        "\n",
        "for directory in directories:\n",
        "    for subdirectory in subdirectories:\n",
        "        path = os.path.join(path_main, directory, subdirectory)\n",
        "        file_count = len(os.listdir(path))\n",
        "        print(f\"Number of files in {path}: {file_count}\")"
      ],
      "metadata": {
        "id": "fzGlWjy2Y45R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = f'{path_main}/train'\n",
        "test_path = f'{path_main}/test'\n",
        "valid_path  = f'{path_main}/valid'\n",
        "\n",
        "test_path"
      ],
      "metadata": {
        "id": "DVXEFebbY6uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    f\"train: {train_path}\\n\"\n",
        "    f\"test: {test_path}\\n\"\n",
        "    f\"val: {valid_path}\\n\"\n",
        "    f\"nc: {1}\\n\"\n",
        "    f\"names: HopCar\",\n",
        ")\n",
        "\n",
        "with open(\"data.yaml\", \"w\") as file:\n",
        "    yaml.dump({\n",
        "        \"train\": train_path,\n",
        "        \"test\": test_path,\n",
        "        \"val\": valid_path,\n",
        "        \"nc\": 1,\n",
        "        \"names\": {0: \"HopCar\"}\n",
        "    }, file)"
      ],
      "metadata": {
        "id": "2cPwyh_iY_Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete old results if exists\n",
        "wildcard = f\"{PROJECT_NAME}/feature_extraction*\"\n",
        "! rm -r $wildcard"
      ],
      "metadata": {
        "id": "UVZ4B3MKZBRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov5/train.py --batch $TRAIN_BATCH --epochs $TRAIN_EPOCHS --data \"data.yaml\" --weights $BASE_MODEL --project $PROJECT_NAME --name 'feature_extraction' --cache --freeze 12"
      ],
      "metadata": {
        "id": "Sz8kmU5EZC9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete old results\n",
        "wildcard = f\"{PROJECT_NAME}/validation_on_test_data*\"\n",
        "! rm -r $wildcard"
      ],
      "metadata": {
        "id": "GaP3TnjPZG73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WEIGHTS_BEST = f\"{PROJECT_NAME}/feature_extraction/weights/best.pt\"\n",
        "! python yolov5/val.py --weights $WEIGHTS_BEST --batch $VAL_BATCH --data 'data.yaml' --task test --project $PROJECT_NAME --name 'validation_on_test_data' --augment"
      ],
      "metadata": {
        "id": "JjQ9cYUYZKax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete old results\n",
        "wildcard = f\"{PROJECT_NAME}/detect_test*\"\n",
        "! rm -r $wildcard"
      ],
      "metadata": {
        "id": "zbWiW8rDZM1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pics = ['F1_curve.png', 'PR_curve.png', 'PR_curve.png', 'R_curve.png']\n",
        "\n",
        "fig, axs = plt.subplots(2, 2,figsize=(10, 10))\n",
        "\n",
        "for i, pic in enumerate(pics):\n",
        "    image_path = f'{PROJECT_NAME}/feature_extraction/{pic}'\n",
        "    img = mpimg.imread(image_path)\n",
        "    row = i // 2\n",
        "    col = i % 2\n",
        "    axs[row, col].imshow(img)\n",
        "    axs[row, col].axis('off')\n",
        "    axs[row, col].set_title(pic[:-4].replace(\"_\", \" \").upper())\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KmlqX2DKZOhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pics = ['confusion_matrix.png', 'labels.jpg', 'labels_correlogram.jpg', 'results.png']\n",
        "\n",
        "fig, axs = plt.subplots(4, 1, figsize=(8, 24))  # Adjust figsize as desired\n",
        "\n",
        "for i, pic in enumerate(pics):\n",
        "    image_path = f'{PROJECT_NAME}/feature_extraction/{pic}'\n",
        "    img = mpimg.imread(image_path)\n",
        "    axs[i].imshow(img)\n",
        "    axs[i].axis('off')\n",
        "    axs[i].set_title(pic[:-4].replace(\"_\", \" \").upper())\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MwPsMIC3ZQhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pics = ['val_batch0_labels.jpg', 'val_batch0_pred.jpg']\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(20, 10))  # Adjust figsize as desired\n",
        "\n",
        "for i, pic in enumerate(pics):\n",
        "    image_path = f'{PROJECT_NAME}/feature_extraction/{pic}'\n",
        "    img = mpimg.imread(image_path)\n",
        "    axs[i].imshow(img)\n",
        "    axs[i].axis('off')\n",
        "    axs[i].set_title(pic[:-4].replace(\"_\", \" \").upper())\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vvg9OXiaZSXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov5/detect.py --weights $WEIGHTS_BEST --conf 0.6 --source '/content/tmp/images' --project $PROJECT_NAME --name 'detect_test' --augment --line=3 --save-txt"
      ],
      "metadata": {
        "id": "t4LtuCsuZXTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = \"yolov5_train/detect_test\"\n",
        "jpg_files = [file for file in os.listdir(directory) if file.endswith(\".jpg\")]\n",
        "random_files = random.sample(jpg_files, 5)\n",
        "\n",
        "for file in random_files:\n",
        "    image_path = os.path.join(directory, file)\n",
        "    image = mpimg.imread(image_path)\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ChJZuFHLZhDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the output folder for cropped images\n",
        "output_folder = \"cropped_images\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Path to the directory containing the labeled images\n",
        "label_folder = \"yolov5_train/detect_test/labels\"\n",
        "\n",
        "# Process each labeled image\n",
        "for label_file in os.listdir(label_folder):\n",
        "    image_name = label_file[:-4] + \".jpg\"\n",
        "    image_path = os.path.join(image_folder, image_name)\n",
        "    label_path = os.path.join(label_folder, label_file)\n",
        "    image = cv2.imread(image_path)\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Read the label file\n",
        "    with open(label_path, \"r\") as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Process each line in the label file\n",
        "    for line in lines:\n",
        "        class_id, x_center, y_center, box_width, box_height = map(float, line.strip().split())\n",
        "\n",
        "        # Calculate bounding box coordinates\n",
        "        x_min = int((x_center - box_width / 2) * width)\n",
        "        y_min = int((y_center - box_height / 2) * height)\n",
        "        x_max = int((x_center + box_width / 2) * width)\n",
        "        y_max = int((y_center + box_height / 2) * height)\n",
        "\n",
        "        # Crop and save the image using the bounding box coordinates\n",
        "        cropped_img = image[y_min:y_max, x_min:x_max]\n",
        "        cropped_img_name = f'{image_name[:-4]}_{int(class_id)}.jpg'\n",
        "        cropped_img_path = os.path.join(output_folder, cropped_img_name)\n",
        "        cv2.imwrite(cropped_img_path, cropped_img)"
      ],
      "metadata": {
        "id": "oPqWISfVZk3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Path to the output folder for cropped images\n",
        "output_folder = \"cropped_images\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Path to the directory containing the labeled images\n",
        "label_folder = \"yolov5_train/detect_test/labels\"\n",
        "image_folder = \"/content/tmp/images\"\n",
        "\n",
        "# Randomly select 5 images\n",
        "image_files = os.listdir(label_folder)\n",
        "random_images = random.sample(image_files, 5)\n",
        "\n",
        "# Create a figure to display the images\n",
        "fig, axs = plt.subplots(5, 2, figsize=(10, 20))\n",
        "\n",
        "# Process each randomly selected image\n",
        "for i, image_file in enumerate(random_images):\n",
        "    image_name = image_file[:-4] + \".jpg\"\n",
        "    image_path = os.path.join(image_folder, image_name)\n",
        "    label_path = os.path.join(label_folder, image_file)\n",
        "    image = cv2.imread(image_path)\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Read the label file\n",
        "    with open(label_path, \"r\") as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Process the first bounding box in the label file\n",
        "    line = lines[0]\n",
        "    class_id, x_center, y_center, box_width, box_height = map(float, line.strip().split())\n",
        "\n",
        "    # Calculate bounding box coordinates\n",
        "    x_min = int((x_center - box_width / 2) * width)\n",
        "    y_min = int((y_center - box_height / 2) * height)\n",
        "    x_max = int((x_center + box_width / 2) * width)\n",
        "    y_max = int((y_center + box_height / 2) * height)\n",
        "\n",
        "    # Crop the image using the bounding box coordinates\n",
        "    cropped_img = image[y_min:y_max, x_min:x_max]\n",
        "\n",
        "    # Display the uncropped image\n",
        "    axs[i, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    axs[i, 0].axis(\"off\")\n",
        "    axs[i, 0].set_title(\"Uncropped Image\")\n",
        "\n",
        "    # Display the cropped image\n",
        "    axs[i, 1].imshow(cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB))\n",
        "    axs[i, 1].axis(\"off\")\n",
        "    axs[i, 1].set_title(\"Cropped Image\")\n",
        "\n",
        "# Adjust the spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the figure\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tJrGrZCIZoKH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}