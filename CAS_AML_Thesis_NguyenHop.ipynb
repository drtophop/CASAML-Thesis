{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXfCKMub0utix0IKPDwkRv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drtophop/CASAML-Thesis/blob/main/CAS_AML_Thesis_NguyenHop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dcda3e5-ad82-472c-bc72-5310a1e59683"
      },
      "source": [
        "# CAS AML Thesis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "RP6iW0pm11q6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scope"
      ],
      "metadata": {
        "id": "x9T7lebI6Vq3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Contents"
      ],
      "metadata": {
        "id": "W6SlaM6Y1-Si"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sources"
      ],
      "metadata": {
        "id": "FEqRMsT72Mg6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remarks"
      ],
      "metadata": {
        "id": "C8uZGoGP6ZVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries and Modules"
      ],
      "metadata": {
        "id": "OZ0gVTtB5-yJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "EJcI1g4rYETg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import  time, random\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "dNQggfP-XvBq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "GkQHhQ0sX08x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "from IPython.display import clear_output\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "w43wbFBYX3RJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml"
      ],
      "metadata": {
        "id": "s4y-vwhCX7CZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ],
      "metadata": {
        "id": "GghZXjVcX9H7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import io\n",
        "import cv2\n",
        "import json"
      ],
      "metadata": {
        "id": "qE_thxM5X_Hz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "KWcdBGLTYBgR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Numpy"
      ],
      "metadata": {
        "id": "W2Od1BeZ6GPm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Opendatasets"
      ],
      "metadata": {
        "id": "B24N-dSK-_QG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The opendatasets Python package, provides a convenient way to download and work with open datasets from various sources"
      ],
      "metadata": {
        "id": "WsQC_QUK_VXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "id": "zVSvlT_u-8ue",
        "outputId": "45400f0f-7135-4737-9e9f-5eb2058320db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.65.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.13)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.27.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.26.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od"
      ],
      "metadata": {
        "id": "rnNKpaOYaWz4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Clear locals"
      ],
      "metadata": {
        "id": "T7bmbKBg7LsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before starting with the Yolov5, existing contents and existing folders from a potentional former execution of this Notebook will be cleared to show proper execution, by following expressions"
      ],
      "metadata": {
        "id": "eupjOGmu8hlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dirs_to_delete = ['car-object-detection', 'yolov5', 'test', 'tmp', 'train', 'valid', 'yolov5_train']\n",
        "\n",
        "for dir_to_delete in dirs_to_delete:\n",
        "    path_del = os.path.join(path_main, dir_to_delete)\n",
        "    if os.path.exists(path_del):\n",
        "        shutil.rmtree(path_del)\n",
        "\n",
        "files_to_delete = ['data.yaml','yolov5m6.pt']\n",
        "\n",
        "for file_to_delete in files_to_delete:\n",
        "    file_del = os.path.join(path_main, file_to_delete)\n",
        "    if os.path.exists(file_del):\n",
        "        os.remove(file_del)"
      ],
      "metadata": {
        "id": "a2hEQs2H9SA_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the String for the detection dataset folder\n",
        "path_yoloset = f'{path_main}/car-object-detection/data'"
      ],
      "metadata": {
        "id": "UsCXoMQZ8FJd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets"
      ],
      "metadata": {
        "id": "93Mpzn8x6Iou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Local Folder"
      ],
      "metadata": {
        "id": "EP_BIGwi7i0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_main = os.getcwd()"
      ],
      "metadata": {
        "id": "8MAJMQIK7oev"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Object Recognition"
      ],
      "metadata": {
        "id": "PWvWM4q86Pie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "od.download('https://www.kaggle.com/datasets/sshikamaru/car-object-detection/download?datasetVersionNumber=2')"
      ],
      "metadata": {
        "id": "Eg7dqn5DYSMZ",
        "outputId": "986cccc0-da00-4db6-e0f8-75245c91653f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: drtophop\n",
            "Your Kaggle Key: ··········\n",
            "Downloading car-object-detection.zip to ./car-object-detection\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 112M/112M [00:05<00:00, 22.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Object Segmentation"
      ],
      "metadata": {
        "id": "NjiVGRsp6fBt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Object Recoginition with Yolov5"
      ],
      "metadata": {
        "id": "4ZnMlbXc7CdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clone and Setup Yolo V5"
      ],
      "metadata": {
        "id": "FmFuOUmQ9rfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone yolov5 from the corresponding Git Repository to Local\n",
        "!git clone https://github.com/ultralytics/yolov5"
      ],
      "metadata": {
        "id": "fStg9AF49o0O",
        "outputId": "8328e21e-36a4-4dea-994d-cb46fb496293",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15978, done.\u001b[K\n",
            "remote: Counting objects: 100% (147/147), done.\u001b[K\n",
            "remote: Compressing objects: 100% (77/77), done.\u001b[K\n",
            "remote: Total 15978 (delta 89), reused 110 (delta 70), pack-reused 15831\u001b[K\n",
            "Receiving objects: 100% (15978/15978), 14.54 MiB | 24.90 MiB/s, done.\n",
            "Resolving deltas: 100% (10963/10963), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the required Python packages specified in the requirements.txt file within the yolov5 directory\n",
        "!pip install -qr yolov5/requirements.txt"
      ],
      "metadata": {
        "id": "rtlMtyfV-Yp_",
        "outputId": "398cd4df-f8e8-4d5d-c025-4c24490566b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m595.6/595.6 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialization"
      ],
      "metadata": {
        "id": "yuxoMnhzAjVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up the Hyperparameters to run yolov5"
      ],
      "metadata": {
        "id": "jyuUu1nuBN8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_NAME = \"yolov5_train\"\n",
        "BASE_MODEL = \"yolov5m6.pt\"\n",
        "TRAIN_BATCH = 32\n",
        "TRAIN_EPOCHS = 20\n",
        "VAL_BATCH = 64\n",
        "\n",
        "\n",
        "# Doublecheck if needed Folders are ok\n",
        "print(f'does path_main exist: {os.path.exists(path_main)}')\n",
        "print(f'does path_yoloset exist: {os.path.exists(path_yoloset)}')"
      ],
      "metadata": {
        "id": "tfCOZi_k-t8l",
        "outputId": "037f1f05-7750-4073-c36e-77623dd71fcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "does path_main exist: True\n",
            "does path_yoloset exist: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_h, img_w, num_channels = (380, 676, 3)\n",
        "\n",
        "df = pd.read_csv(f'{path_yoloset}/train_solution_bounding_boxes (1).csv')\n",
        "\n",
        "df.rename(columns={'image':'image_id'}, inplace=True)\n",
        "df['image_id'] = df['image_id'].apply(lambda x: x.split('.')[0])\n",
        "df['x_center'] = (df['xmin'] + df['xmax'])/2\n",
        "df['y_center'] = (df['ymin'] + df['ymax'])/2\n",
        "df['w'] = df['xmax'] - df['xmin']\n",
        "df['h'] = df['ymax'] - df['ymin']\n",
        "df['classes'] = 0\n",
        "df['x_center'] = df['x_center']/img_w\n",
        "df['w'] = df['w']/img_w\n",
        "df['y_center'] = df['y_center']/img_h\n",
        "df['h'] = df['h']/img_h\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "zJtMkDMLYk2K",
        "outputId": "3fb1709b-0643-42e7-a28e-9cca949e2900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-a0b9330cf2d3>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m380\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m676\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{path_yoloset}/train_solution_bounding_boxes (1).csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'image_id'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/car-object-detection/data/train_solution_bounding_boxes (1).csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = list(set(df.image_id))\n",
        "image = random.choice(index)\n",
        "print(\"Image ID: %s\"%(image))\n",
        "\n",
        "img = cv2.imread(f'{path_yoloset}/training_images/{image}.jpg')\n",
        "img.shape"
      ],
      "metadata": {
        "id": "2SbTFZU0Yn_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adde here cose"
      ],
      "metadata": {
        "id": "CAVazeKaYoqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source = 'training_images'\n",
        "\n",
        "for name, mini in tqdm(df.groupby('image_id')):\n",
        "    if not os.path.exists(os.path.join(path_main, 'tmp', 'labels')):\n",
        "        os.makedirs(os.path.join(path_main, 'tmp', 'labels'))\n",
        "\n",
        "    with open(os.path.join(path_main, 'tmp', 'labels', '{}.txt'.format(name)), 'w+') as f:\n",
        "        row = mini[['classes', 'x_center', 'y_center', 'w', 'h']].astype(float).values\n",
        "        row = row.astype(str)\n",
        "        for j in range(len(row)):\n",
        "            text = ' '.join(row[j])\n",
        "            f.write(text)\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    if not os.path.exists(os.path.join(path_main, 'tmp', 'images')):\n",
        "        os.makedirs(os.path.join(path_main, 'tmp', 'images'))\n",
        "\n",
        "    shutil.copy(\n",
        "        os.path.join(path_yoloset, source, '{}.jpg'.format(name)),\n",
        "        os.path.join(path_main, 'tmp', 'images', '{}.jpg'.format(name))"
      ],
      "metadata": {
        "id": "Rw7QRpbTYrfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGES_PATH = f'{path_main}/tmp/images/'\n",
        "LABELS_PATH = f'{path_main}/tmp/labels/'\n",
        "os.path.exists(IMAGES_PATH)"
      ],
      "metadata": {
        "id": "LbyLyCKQYupZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read labels\n",
        "labels = os.listdir(LABELS_PATH)\n",
        "\n",
        "\n",
        "# Split data\n",
        "train, test = train_test_split(labels, test_size=0.15, shuffle=True)\n",
        "valid, test = train_test_split(test, test_size=0.2)\n",
        "\n",
        "print(f\"train: {len(train)}; valid: {len(valid)}; test: {len(test)}\")"
      ],
      "metadata": {
        "id": "hlEZksLsYyLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(f'{path_main}/test/images')\n",
        "os.makedirs(f'{path_main}/test/labels')\n",
        "os.makedirs(f'{path_main}/train/images')\n",
        "os.makedirs(f'{path_main}/train/labels')\n",
        "os.makedirs(f'{path_main}/valid/images')\n",
        "os.makedirs(f'{path_main}/valid/labels')"
      ],
      "metadata": {
        "id": "9ZqThILLY0px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to move files to directory\n",
        "def move_files_to_dir(files, dirname):\n",
        "    # Create target directories if they don't exist\n",
        "    os.makedirs(f'{path_main}/{dirname}/images', exist_ok=True)\n",
        "    os.makedirs(f'{path_main}/{dirname}/labels', exist_ok=True)\n",
        "\n",
        "    for label_filename in files:\n",
        "        image_filename = f\"{label_filename[:-4]}.jpg\"\n",
        "        shutil.copy(f\"{IMAGES_PATH}/{image_filename}\", f\"{path_main}/{dirname}/images/{image_filename}\")\n",
        "        shutil.copy(f\"{LABELS_PATH}/{label_filename}\", f\"{path_main}/{dirname}/labels/{label_filename}\")\n",
        "\n",
        "\n",
        "# Move splits to folders\n",
        "move_files_to_dir(train, \"train\")\n",
        "move_files_to_dir(test, \"test\")\n",
        "move_files_to_dir(valid, \"valid\")\n"
      ],
      "metadata": {
        "id": "WBTGFMBjY2d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directories = ['train', 'test', 'valid']\n",
        "subdirectories = ['images', 'labels']\n",
        "\n",
        "for directory in directories:\n",
        "    for subdirectory in subdirectories:\n",
        "        path = os.path.join(path_main, directory, subdirectory)\n",
        "        file_count = len(os.listdir(path))\n",
        "        print(f\"Number of files in {path}: {file_count}\")"
      ],
      "metadata": {
        "id": "fzGlWjy2Y45R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = f'{path_main}/train'\n",
        "test_path = f'{path_main}/test'\n",
        "valid_path  = f'{path_main}/valid'\n",
        "\n",
        "test_path"
      ],
      "metadata": {
        "id": "DVXEFebbY6uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    f\"train: {train_path}\\n\"\n",
        "    f\"test: {test_path}\\n\"\n",
        "    f\"val: {valid_path}\\n\"\n",
        "    f\"nc: {1}\\n\"\n",
        "    f\"names: HopCar\",\n",
        ")\n",
        "\n",
        "with open(\"data.yaml\", \"w\") as file:\n",
        "    yaml.dump({\n",
        "        \"train\": train_path,\n",
        "        \"test\": test_path,\n",
        "        \"val\": valid_path,\n",
        "        \"nc\": 1,\n",
        "        \"names\": {0: \"HopCar\"}\n",
        "    }, file)"
      ],
      "metadata": {
        "id": "2cPwyh_iY_Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete old results if exists\n",
        "wildcard = f\"{PROJECT_NAME}/feature_extraction*\"\n",
        "! rm -r $wildcard"
      ],
      "metadata": {
        "id": "UVZ4B3MKZBRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov5/train.py --batch $TRAIN_BATCH --epochs $TRAIN_EPOCHS --data \"data.yaml\" --weights $BASE_MODEL --project $PROJECT_NAME --name 'feature_extraction' --cache --freeze 12"
      ],
      "metadata": {
        "id": "Sz8kmU5EZC9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete old results\n",
        "wildcard = f\"{PROJECT_NAME}/validation_on_test_data*\"\n",
        "! rm -r $wildcard"
      ],
      "metadata": {
        "id": "GaP3TnjPZG73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WEIGHTS_BEST = f\"{PROJECT_NAME}/feature_extraction/weights/best.pt\"\n",
        "! python yolov5/val.py --weights $WEIGHTS_BEST --batch $VAL_BATCH --data 'data.yaml' --task test --project $PROJECT_NAME --name 'validation_on_test_data' --augment"
      ],
      "metadata": {
        "id": "JjQ9cYUYZKax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete old results\n",
        "wildcard = f\"{PROJECT_NAME}/detect_test*\"\n",
        "! rm -r $wildcard"
      ],
      "metadata": {
        "id": "zbWiW8rDZM1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pics = ['F1_curve.png', 'PR_curve.png', 'PR_curve.png', 'R_curve.png']\n",
        "\n",
        "fig, axs = plt.subplots(2, 2,figsize=(10, 10))\n",
        "\n",
        "for i, pic in enumerate(pics):\n",
        "    image_path = f'{PROJECT_NAME}/feature_extraction/{pic}'\n",
        "    img = mpimg.imread(image_path)\n",
        "    row = i // 2\n",
        "    col = i % 2\n",
        "    axs[row, col].imshow(img)\n",
        "    axs[row, col].axis('off')\n",
        "    axs[row, col].set_title(pic[:-4].replace(\"_\", \" \").upper())\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KmlqX2DKZOhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pics = ['confusion_matrix.png', 'labels.jpg', 'labels_correlogram.jpg', 'results.png']\n",
        "\n",
        "fig, axs = plt.subplots(4, 1, figsize=(8, 24))  # Adjust figsize as desired\n",
        "\n",
        "for i, pic in enumerate(pics):\n",
        "    image_path = f'{PROJECT_NAME}/feature_extraction/{pic}'\n",
        "    img = mpimg.imread(image_path)\n",
        "    axs[i].imshow(img)\n",
        "    axs[i].axis('off')\n",
        "    axs[i].set_title(pic[:-4].replace(\"_\", \" \").upper())\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MwPsMIC3ZQhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pics = ['val_batch0_labels.jpg', 'val_batch0_pred.jpg']\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(20, 10))  # Adjust figsize as desired\n",
        "\n",
        "for i, pic in enumerate(pics):\n",
        "    image_path = f'{PROJECT_NAME}/feature_extraction/{pic}'\n",
        "    img = mpimg.imread(image_path)\n",
        "    axs[i].imshow(img)\n",
        "    axs[i].axis('off')\n",
        "    axs[i].set_title(pic[:-4].replace(\"_\", \" \").upper())\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vvg9OXiaZSXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov5/detect.py --weights $WEIGHTS_BEST --conf 0.6 --source '/content/tmp/images' --project $PROJECT_NAME --name 'detect_test' --augment --line=3 --save-txt"
      ],
      "metadata": {
        "id": "t4LtuCsuZXTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = \"yolov5_train/detect_test\"\n",
        "jpg_files = [file for file in os.listdir(directory) if file.endswith(\".jpg\")]\n",
        "random_files = random.sample(jpg_files, 5)\n",
        "\n",
        "for file in random_files:\n",
        "    image_path = os.path.join(directory, file)\n",
        "    image = mpimg.imread(image_path)\n",
        "    plt.imshow(image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ChJZuFHLZhDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the output folder for cropped images\n",
        "output_folder = \"cropped_images\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Path to the directory containing the labeled images\n",
        "label_folder = \"yolov5_train/detect_test/labels\"\n",
        "\n",
        "# Process each labeled image\n",
        "for label_file in os.listdir(label_folder):\n",
        "    image_name = label_file[:-4] + \".jpg\"\n",
        "    image_path = os.path.join(image_folder, image_name)\n",
        "    label_path = os.path.join(label_folder, label_file)\n",
        "    image = cv2.imread(image_path)\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Read the label file\n",
        "    with open(label_path, \"r\") as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Process each line in the label file\n",
        "    for line in lines:\n",
        "        class_id, x_center, y_center, box_width, box_height = map(float, line.strip().split())\n",
        "\n",
        "        # Calculate bounding box coordinates\n",
        "        x_min = int((x_center - box_width / 2) * width)\n",
        "        y_min = int((y_center - box_height / 2) * height)\n",
        "        x_max = int((x_center + box_width / 2) * width)\n",
        "        y_max = int((y_center + box_height / 2) * height)\n",
        "\n",
        "        # Crop and save the image using the bounding box coordinates\n",
        "        cropped_img = image[y_min:y_max, x_min:x_max]\n",
        "        cropped_img_name = f'{image_name[:-4]}_{int(class_id)}.jpg'\n",
        "        cropped_img_path = os.path.join(output_folder, cropped_img_name)\n",
        "        cv2.imwrite(cropped_img_path, cropped_img)"
      ],
      "metadata": {
        "id": "oPqWISfVZk3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Path to the output folder for cropped images\n",
        "output_folder = \"cropped_images\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Path to the directory containing the labeled images\n",
        "label_folder = \"yolov5_train/detect_test/labels\"\n",
        "image_folder = \"/content/tmp/images\"\n",
        "\n",
        "# Randomly select 5 images\n",
        "image_files = os.listdir(label_folder)\n",
        "random_images = random.sample(image_files, 5)\n",
        "\n",
        "# Create a figure to display the images\n",
        "fig, axs = plt.subplots(5, 2, figsize=(10, 20))\n",
        "\n",
        "# Process each randomly selected image\n",
        "for i, image_file in enumerate(random_images):\n",
        "    image_name = image_file[:-4] + \".jpg\"\n",
        "    image_path = os.path.join(image_folder, image_name)\n",
        "    label_path = os.path.join(label_folder, image_file)\n",
        "    image = cv2.imread(image_path)\n",
        "    height, width, _ = image.shape\n",
        "\n",
        "    # Read the label file\n",
        "    with open(label_path, \"r\") as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Process the first bounding box in the label file\n",
        "    line = lines[0]\n",
        "    class_id, x_center, y_center, box_width, box_height = map(float, line.strip().split())\n",
        "\n",
        "    # Calculate bounding box coordinates\n",
        "    x_min = int((x_center - box_width / 2) * width)\n",
        "    y_min = int((y_center - box_height / 2) * height)\n",
        "    x_max = int((x_center + box_width / 2) * width)\n",
        "    y_max = int((y_center + box_height / 2) * height)\n",
        "\n",
        "    # Crop the image using the bounding box coordinates\n",
        "    cropped_img = image[y_min:y_max, x_min:x_max]\n",
        "\n",
        "    # Display the uncropped image\n",
        "    axs[i, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    axs[i, 0].axis(\"off\")\n",
        "    axs[i, 0].set_title(\"Uncropped Image\")\n",
        "\n",
        "    # Display the cropped image\n",
        "    axs[i, 1].imshow(cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB))\n",
        "    axs[i, 1].axis(\"off\")\n",
        "    axs[i, 1].set_title(\"Cropped Image\")\n",
        "\n",
        "# Adjust the spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the figure\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tJrGrZCIZoKH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}